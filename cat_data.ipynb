{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/Users/Suncicie/Study/DataMining/Competition/Vips\")\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_action_train=pd.read_table(\"data/user_action_train.txt\",header=None)\n",
    "# goods=pd.read_table(\"data/goods_train.txt\",header=None)\n",
    "# user_action_test=pd.read_table(\"data/user_action_test_items.txt\",header=None)\n",
    "# \n",
    "# user_action_train.columns=[\"user_id\",\"spu_id\",\"bought\",\"date\"]\n",
    "# user_action_test.columns=[\"user_id\",\"spu_id\",\"prob\"]\n",
    "# goods.columns=[\"spu_id\",\"brand_id\",\"cat_id\"]\n",
    "# \n",
    "# # first the lr\n",
    "# train=pd.merge(user_action_train,goods,on=\"spu_id\",how=\"left\")\n",
    "# test=pd.merge(user_action_test,goods,on=\"spu_id\",how=\"left\")\n",
    "\n",
    "print train.head()\n",
    "print test.head()\n",
    "\n",
    "dump_path_train=\"data/origin_train.pkl\"\n",
    "dump_path_test=\"data/origin_test.pkl\"\n",
    "pickle.dump(train, open(dump_path_train, 'w'))\n",
    "pickle.dump(test, open(dump_path_test, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  spu_id  bought   date    brand_id  cat_id  click_count  \\\n0   320510  839213       0  03-10  10010631.0   271.0          141   \n1   314210  369282       0  01-05  10001351.0   311.0          489   \n2   381441  730484       0  01-05  10000866.0   311.0           39   \n3   168858  902515       0  03-10  10028088.0   297.0          170   \n4   270694  953270       0  01-30  10000223.0  1056.0          335   \n\n   bought_count  bought_rate  \n0             0          0.0  \n1             2          4.0  \n2             0          0.0  \n3             0          0.0  \n4             4         12.0  \n   user_id   spu_id  prob  brand_id  cat_id  click_count  bought_count  \\\n0    60750  1580520   NaN  10012892   28008          203             4   \n1   595361   484220   NaN  10005367     311          296             0   \n2    45427   326736   NaN  10004119   28006         1248            21   \n3   443345  1049603   NaN  10012721     680          379             2   \n4   318510    74820   NaN  10004119   28006          997             5   \n\n   bought_rate  \n0         20.0  \n1          0.0  \n2         17.0  \n3          5.0  \n4          5.0  \n"
     ]
    }
   ],
   "source": [
    "# ---construct the sum of a user bought in the 3 months\n",
    "# ---instslled_count = dfInstalled[['userID','count']].groupby('userID').sum().reset_index()\n",
    "\n",
    "UserClickDF=train[[\"user_id\",\"bought\"]].groupby(\"user_id\").count().reset_index()\n",
    "UserClickDF.columns=[\"user_id\",\"click_count\"]\n",
    "print UserClickDF.head()\n",
    "# # # # # \n",
    "UserBoughtDF=train[[\"user_id\",\"bought\"]].groupby(\"user_id\").sum().reset_index()\n",
    "UserBoughtDF.columns=[\"user_id\",\"bought_count\"]\n",
    "print UserBoughtDF.head()\n",
    "# # \n",
    "\n",
    "# print train.columns\n",
    "# print test.columns\n",
    "train=pd.merge(train,UserClickDF,on=\"user_id\",how=\"left\")\n",
    "test=pd.merge(test,UserClickDF,on=\"user_id\",how=\"left\")\n",
    "# # # # \n",
    "# print train.columns\n",
    "# print test.columns\n",
    "train=pd.merge(train,UserBoughtDF,on=\"user_id\",how=\"left\")\n",
    "test=pd.merge(test,UserBoughtDF,on=\"user_id\",how=\"left\")\n",
    "# # # \n",
    "# # # \n",
    "# print train.columns\n",
    "# print test.columns\n",
    "# \n",
    "\n",
    "train[\"bought_rate\"]=np.rint(((train[\"bought_count\"]/train[\"click_count\"])*100000000)/100000)\n",
    "test[\"bought_rate\"]=np.rint(((test[\"bought_count\"]/test[\"click_count\"])*100000000)/100000)\n",
    "print train.head()\n",
    "print test.head()\n",
    "\n",
    "# construct the sum of a user click in the 3 months\n",
    "# construct the sum of a user bought in the 3 months\n",
    "# construct the rate of bought/click in the 3 months\n",
    "# construct the mean bought of a month #this has no sense for it have sum as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id    brand_id  brand_id_count\n0        3  10004318.0              19\n1        3  10005367.0              18\n2        3  10013106.0              17\n3        3  10020991.0              17\n4        3  10000601.0              14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  brand_count\n0        3          108\n1        4           60\n2       11           21\n3       16           17\n4       17          407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  goods_count\n0        3          336\n1        4          189\n2       11           63\n3       16           31\n4       17         2435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  cat_id  cat_count\n0        3   311.0        123\n1        3  1056.0         46\n2        3  1012.0         45\n3        3   297.0         36\n4        3   271.0         23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  spu_id  bought   date    brand_id  cat_id  click_count  \\\n0   320510  839213       0  03-10  10010631.0   271.0          141   \n1   314210  369282       0  01-05  10001351.0   311.0          489   \n2   381441  730484       0  01-05  10000866.0   311.0           39   \n3   168858  902515       0  03-10  10028088.0   297.0          170   \n4   270694  953270       0  01-30  10000223.0  1056.0          335   \n\n   bought_count  bought_rate  brand_count  goods_count  goods/brands  \\\n0             0          0.0           56          141           3.0   \n1             2          4.0          130          489           4.0   \n2             0          0.0           17           39           2.0   \n3             0          0.0           76          170           2.0   \n4             4         12.0           79          335           4.0   \n\n   cat_count  goods/cats  brands/cat  \n0         10        14.0         6.0  \n1          9        54.0        14.0  \n2          8         5.0         2.0  \n3          5        34.0        15.0  \n4         17        20.0         5.0  \n   user_id   spu_id  prob  brand_id  cat_id  click_count  bought_count  \\\n0    60750  1580520   NaN  10012892   28008          203             4   \n1   595361   484220   NaN  10005367     311          296             0   \n2    45427   326736   NaN  10004119   28006         1248            21   \n3   443345  1049603   NaN  10012721     680          379             2   \n4   318510    74820   NaN  10004119   28006          997             5   \n\n   bought_rate  brand_count  goods_count  goods/brands  cat_count  goods/cats  \\\n0         20.0           98          203           2.0         19        11.0   \n1          0.0           78          296           4.0          9        33.0   \n2         17.0          311         1248           4.0         17        73.0   \n3          5.0           83          379           5.0         12        32.0   \n4          5.0          191          997           5.0         22        45.0   \n\n   brands/cat  \n0         5.0  \n1         9.0  \n2        18.0  \n3         7.0  \n4         9.0  \n"
     ]
    }
   ],
   "source": [
    "# encoding=\"utf-8\"\n",
    "# ---the feature about brand, it show whether a user like buy one brand\n",
    "# the number of a user cat brand in 3 month \n",
    "UserClickBrand=train.groupby([\"user_id\"])[\"brand_id\"].value_counts()\n",
    "UserClickBrand=UserClickBrand.rename(\"brand_id_count\").reset_index()\n",
    "print UserClickBrand.head()\n",
    "# #  user_id    brand_id  brand_id_count\n",
    "# # 0        3  10004318.0              19\n",
    "# # 1        3  10005367.0              18\n",
    "# # 2        3  10013106.0              17\n",
    "# # 3        3  10020991.0              17\n",
    "# # 4        3  10000601.0              14\n",
    "# # \n",
    "UserClickBrandCount=UserClickBrand.groupby([\"user_id\"])[\"brand_id\"].count().reset_index()\n",
    "UserClickBrandCount.columns=[\"user_id\",\"brand_count\"]\n",
    "print UserClickBrandCount.head()\n",
    "#   # user_id  brand_id\n",
    "# # 0        3       108\n",
    "# # 1        4        60\n",
    "# # 2       11        21\n",
    "# # 3       16        17\n",
    "# # 4       17       407\n",
    "train=pd.merge(train,UserClickBrandCount,on=\"user_id\",how=\"left\")\n",
    "test=pd.merge(test,UserClickBrandCount,on=\"user_id\",how=\"left\")\n",
    "# # \n",
    "# # # ---the number of a user cat goods in 3 month\n",
    "# # # print UserClickBrand2.head()\n",
    "UserClickGoodsCount=UserClickBrand.groupby([\"user_id\"])[\"brand_id_count\"].sum().reset_index()\n",
    "UserClickGoodsCount.columns=[\"user_id\",\"goods_count\"]\n",
    "print UserClickGoodsCount.head()\n",
    "# \n",
    "train=pd.merge(train,UserClickGoodsCount,on=\"user_id\",how=\"left\")\n",
    "test=pd.merge(test,UserClickGoodsCount,on=\"user_id\",how=\"left\")\n",
    "# print test.head()\n",
    "# print train.head()\n",
    "\n",
    "\n",
    "# ---the rate of num of goods/num of brands 买一个商品（用类别来衡量）看的牌子种类多不多\n",
    "\n",
    "train[\"goods/brands\"]=np.rint(train[\"goods_count\"]/train[\"brand_count\"])\n",
    "test[\"goods/brands\"]=np.rint(test[\"goods_count\"]/test[\"brand_count\"])\n",
    "# \n",
    "# print train.head()\n",
    "# print test.head()\n",
    "\n",
    "# there have an other one\n",
    "\n",
    "# ---the feature about the cat, it shows whether a user like many category\n",
    "UserClickCat=train.groupby([\"user_id\"])[\"cat_id\"].value_counts()\n",
    "UserClickCat=UserClickCat.rename(\"cat_count\").reset_index()\n",
    "print UserClickCat.head()\n",
    "#   user_id  cat_id  cat_count\n",
    "# 0        3   311.0        123\n",
    "# 1        3  1056.0         46\n",
    "# 2        3  1012.0         45\n",
    "# 3        3   297.0         36\n",
    "# 4        3   271.0         23\n",
    "\n",
    "# ---the number of a user cat id in 3 month\n",
    "# ---Don't calculate the mean sum(cat_count)/sum(cat_id)\n",
    "UserClickCatCount=UserClickCat.groupby([\"user_id\"])[\"cat_id\"].count().reset_index()\n",
    "UserClickCatCount.columns=[\"user_id\",\"cat_count\"]\n",
    "train=pd.merge(train,UserClickCatCount,on=\"user_id\",how=\"left\")\n",
    "test=pd.merge(test,UserClickCatCount,on=\"user_id\",how=\"left\")\n",
    "\n",
    "# ---the rate of the goodsnum/catsnum\n",
    "train[\"goods/cats\"]=np.rint(train[\"goods_count\"]/train[\"cat_count\"])\n",
    "test[\"goods/cats\"]=np.rint(test[\"goods_count\"]/test[\"cat_count\"])\n",
    "\n",
    "# ---the feature combine the brand and the cat\n",
    "# a cat he see how many brands  # the rate of a brand ,he cat how many goods, merge on brand 这个是根据商品建模了\n",
    "train[\"brands/cat\"]=np.rint(train[\"brand_count\"]/train[\"cat_count\"])\n",
    "test[\"brands/cat\"]=np.rint(test[\"brand_count\"]/test[\"cat_count\"])\n",
    "print train.head()\n",
    "print test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  spu_id  bought   date    brand_id  cat_id  click_count  \\\n0   320510  839213       0  03-10  10010631.0   271.0          141   \n1   314210  369282       0  01-05  10001351.0   311.0          489   \n2   381441  730484       0  01-05  10000866.0   311.0           39   \n3   168858  902515       0  03-10  10028088.0   297.0          170   \n4   270694  953270       0  01-30  10000223.0  1056.0          335   \n\n   bought_count  bought_rate  brand_count  goods_count  cat_count  goods/cats  \\\n0             0          0.0           56          141         10        14.0   \n1             2          4.0          130          489          9        54.0   \n2             0          0.0           17           39          8         5.0   \n3             0          0.0           76          170          5        34.0   \n4             4         12.0           79          335         17        20.0   \n\n   brands/cat  goods/brands  \n0         6.0           3.0  \n1        14.0           4.0  \n2         2.0           2.0  \n3        15.0           2.0  \n4         5.0           4.0  \n   user_id   spu_id  prob  brand_id  cat_id  click_count  bought_count  \\\n0    60750  1580520   NaN  10012892   28008          203             4   \n1   595361   484220   NaN  10005367     311          296             0   \n2    45427   326736   NaN  10004119   28006         1248            21   \n3   443345  1049603   NaN  10012721     680          379             2   \n4   318510    74820   NaN  10004119   28006          997             5   \n\n   bought_rate  brand_count  goods_count  cat_count  goods/cats  brands/cat  \\\n0         20.0           98          203         19        11.0         5.0   \n1          0.0           78          296          9        33.0         9.0   \n2         17.0          311         1248         17        73.0        18.0   \n3          5.0           83          379         12        32.0         7.0   \n4          5.0          191          997         22        45.0         9.0   \n\n   goods/brands  \n0           2.0  \n1           4.0  \n2           4.0  \n3           5.0  \n4           5.0  \n"
     ]
    }
   ],
   "source": [
    "# train[\"bought_rate\"]=((train[\"bought_count\"]/train[\"click_count\"])*100000000)/100000\n",
    "# test[\"bought_rate\"]=((test[\"bought_count\"]/test[\"click_count\"])*100000000)/100000\n",
    "\n",
    "\n",
    "# train[\"bought_rate\"]=train[\"bought_rate\"]*100000%10000\n",
    "# test[\"bought_rate\"]=test[\"bought_rate\"]*100000%10000\n",
    "\n",
    "# train[\"bought_rate\"]=np.rint(train[\"bought_rate\"])\n",
    "# test[\"bought_rate\"]=np.rint(test[\"bought_rate\"])\n",
    "# \n",
    "# print train[\"bought_rate\"].head()\n",
    "# print test[\"bought_rate\"].head()\n",
    "print train.head()\n",
    "print test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     column_name  missing_count\n0        user_id              0\n1         spu_id              0\n2         bought              0\n3           date              0\n4       brand_id              0\n5         cat_id              0\n6    click_count              0\n7   bought_count              0\n8    bought_rate              0\n9    brand_count              0\n10   goods_count              0\n11  goods/brands              0\n12     cat_count              0\n13    goods/cats              0\n14    brands/cat              0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     column_name  missing_count\n0        user_id              0\n1         spu_id              0\n2           prob        5761091\n3       brand_id              0\n4         cat_id              0\n5    click_count              0\n6   bought_count              0\n7    bought_rate              0\n8    brand_count              0\n9    goods_count              0\n10  goods/brands              0\n11     cat_count              0\n12    goods/cats              0\n13    brands/cat              0\n"
     ]
    }
   ],
   "source": [
    "# cat the na\n",
    "missing_train = train.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "missing_train.columns = ['column_name', 'missing_count']\n",
    "print missing_train\n",
    "# \n",
    "missing_test=test.isnull().sum(axis=0).reset_index()\n",
    "missing_test.columns= ['column_name', 'missing_count']\n",
    "print missing_test\n",
    "\n",
    "\n",
    "# ---del the miss data\n",
    "\n",
    "# train2=train.dropna()\n",
    "# missing_train = train2.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "# missing_train.columns = ['column_name', 'missing_count']\n",
    "# print missing_train\n",
    "\n",
    "\n",
    "# missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "# missing_df = missing_df.sort_values(by='missing_count')\n",
    "\n",
    "#----cat the final data before model\n",
    "# print train2.columns\n",
    "# print test.columns\n",
    "# Index([u'user_id', u'spu_id', u'bought', u'date', u'brand_id_x', u'cat_id',\n",
    "#        u'click_count', u'bought_count', u'bought_rate', u'brand_id_count',\n",
    "#        u'goods_count', u'goods/brands', u'cat_count', u'goods/cats',\n",
    "#        u'brands/cat'],\n",
    "#       dtype='object')\n",
    "# Index([u'user_id', u'spu_id', u'prob', u'brand_id_x', u'cat_id',\n",
    "#        u'click_count', u'bought_count', u'bought_rate', u'brand_id_count',\n",
    "#        u'goods_count', u'goods/brands', u'cat_count', u'goods/cats',\n",
    "#        u'brands/cat'],\n",
    "#       dtype='object')\n",
    "# del test[\"prob\"]\n",
    "# train2=train2.drop([\"date\"],axis=1)\n",
    "# print train.columns\n",
    "# print test.columns\n",
    "# print len(train.columns)\n",
    "# print len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train.shape\n",
    "# print test.shape\n",
    "# train=train.dropna()\n",
    "# test=test.dropna()\n",
    "# print train.shape\n",
    "# print test.shape\n",
    "\n",
    "# missing_train = train.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "# missing_train.columns = ['column_name', 'missing_count']\n",
    "# print missing_train\n",
    "# \n",
    "# missing_test = test.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "# missing_test.columns = ['column_name', 'missing_count']\n",
    "# print missing_test\n",
    "\n",
    "# train=train.dropna()\n",
    "\n",
    "# missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "# missing_df = missing_df.sort_values(by='missing_count')\n",
    "\n",
    "train.to_csv(\"data/train.csv\")\n",
    "test.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_sample=train\n",
    "# test_sample=test\n",
    "# train=train_sample.head()\n",
    "# test=test_sample.head()\n",
    "# print train\n",
    "# print test\n",
    "# train[\"bought\"][3]=1\n",
    "# print train[\"bought\"]\n",
    "\n",
    "# print train_sample.shape\n",
    "# print test_sample.shape\n",
    "# train=train_sample\n",
    "# test=test_sample\n",
    "# print train.shape\n",
    "# print test.shape\n",
    "\n",
    "# missing_train = train.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "# missing_train.columns = ['column_name', 'missing_count']\n",
    "# print missing_train\n",
    "# \n",
    "# missing_test = test.isnull().sum(axis=0).reset_index()# 这里的sum直接统计为True的值\n",
    "# missing_test.columns = ['column_name', 'missing_count']\n",
    "# print missing_test\n",
    "\n",
    "# train=train.dropna()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  bought  bought_count  bought_rate\n0   320510       0             0          0.0\n1   314210       0             2          4.0\n2   381441       0             0          0.0\n3   168858       0             0          0.0\n4   270694       0             4         12.0\n   user_id  bought_count  bought_rate\n0    60750             4         20.0\n1   595361             0          0.0\n2    45427            21         17.0\n3   443345             2          5.0\n4   318510             5          5.0\n"
     ]
    }
   ],
   "source": [
    "train_all=pd.read_csv(\"data/train.csv\")\n",
    "test_all=pd.read_csv(\"data/test.csv\")\n",
    "del train_all[\"Unnamed: 0\"]\n",
    "del test_all[\"Unnamed: 0\"]\n",
    "\n",
    "columns_train=[\"user_id\",\"bought\",\"bought_count\",\"bought_rate\"]\n",
    "columns_test=[\"user_id\",\"bought_count\",\"bought_rate\"]\n",
    "\n",
    "train=train_all[columns_train]\n",
    "test=test_all[columns_test]\n",
    "\n",
    "\n",
    "\n",
    "print train.head()\n",
    "print test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111111111\nuser_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought_count\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-38e11a3fce88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mencd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suncicie/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \"\"\"\n\u001b[1;32m   1957\u001b[0m         return _transform_selected(X, self._transform,\n\u001b[0;32m-> 1958\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m",
      "\u001b[0;32m/Users/suncicie/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/suncicie/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1935\u001b[0m         out = sparse.coo_matrix((data, (row_indices, column_indices)),\n\u001b[1;32m   1936\u001b[0m                                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m                                 dtype=self.dtype).tocsr()\n\u001b[0m\u001b[1;32m   1938\u001b[0m         if (isinstance(self.n_values, six.string_types) and\n\u001b[1;32m   1939\u001b[0m                 self.n_values == 'auto'):\n",
      "\u001b[0;32m/Users/suncicie/anaconda/lib/python2.7/site-packages/scipy/sparse/coo.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0midx_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "y_train=train[\"bought\"].values\n",
    "enc=OneHotEncoder()\n",
    "# feats=[\"user_id\",\"spu_id\",\"brand_id\",\"cat_id\",\"click_count\",\"bought_count\",\"bought_rate\",\"brand_count\",\n",
    "#        \"goods_count\",\"goods/brands\",\"cat_count\",\"goods/cats\",\"brands/cat\"]\n",
    "feats=[\"user_id\",\"bought_count\",\"bought_rate\"]\n",
    "\n",
    "print \"11111111111\"\n",
    "for i,feat in enumerate(feats):\n",
    "    print feat\n",
    "    encd=enc.fit(np.array(list(train[feat])+list(test[feat])).reshape(-1,1))\n",
    "    x_train=encd.transform(train[feat].values.reshape(-1,1))\n",
    "    x_test=encd.transform(test[feat].values.reshape(-1,1))\n",
    "    if i == 0:\n",
    "        X_train, X_test = x_train, x_test\n",
    "    else:\n",
    "        X_train, X_test = sparse.hstack((X_train, x_train)), sparse.hstack((X_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (3, 0)\t1.0\n  (4, 1)\t1.0\n  (1, 2)\t1.0\n  (0, 3)\t1.0\n  (2, 4)\t1.0\n  (1, 5)\t1.0\n  (2, 6)\t1.0\n  (0, 7)\t1.0\n  (3, 8)\t1.0\n  (4, 9)\t1.0\n  (4, 10)\t1.0\n  (2, 11)\t1.0\n  (1, 12)\t1.0\n  (0, 13)\t1.0\n  (3, 14)\t1.0\n  (0, 15)\t1.0\n  (3, 16)\t1.0\n  (1, 17)\t1.0\n  (2, 17)\t1.0\n  (4, 18)\t1.0\n  (2, 19)\t1.0\n  (0, 20)\t1.0\n  (3, 21)\t1.0\n  (4, 22)\t1.0\n  (1, 23)\t1.0\n  :\t:\n  (2, 35)\t1.0\n  (0, 36)\t1.0\n  (3, 37)\t1.0\n  (4, 38)\t1.0\n  (1, 39)\t1.0\n  (2, 40)\t1.0\n  (3, 40)\t1.0\n  (0, 41)\t1.0\n  (1, 42)\t1.0\n  (4, 42)\t1.0\n  (3, 43)\t1.0\n  (2, 44)\t1.0\n  (1, 45)\t1.0\n  (0, 46)\t1.0\n  (4, 47)\t1.0\n  (2, 48)\t1.0\n  (0, 49)\t1.0\n  (4, 50)\t1.0\n  (3, 51)\t1.0\n  (1, 52)\t1.0\n  (2, 53)\t1.0\n  (4, 54)\t1.0\n  (0, 55)\t1.0\n  (1, 56)\t1.0\n  (3, 57)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22222222222\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)\n",
    "print \"22222222222\"\n",
    "proba_test=lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37796232  0.25704719  0.3394084   0.39524905  0.42282906]\n"
     ]
    }
   ],
   "source": [
    "print proba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test.to_csv(\"data/result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}